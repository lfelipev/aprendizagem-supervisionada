{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Eliminations.ipynb","provenance":[{"file_id":"1FD9ObNcfVHWUvKfX2Nk-GSDXFeYs-qhz","timestamp":1574183344084},{"file_id":"1LSoV8tF08t0e8Rb-1KwmgH0V19ppBruz","timestamp":1573036409693}],"collapsed_sections":["TsV0SiuwpZ7i","QaGBc_KwpeVt","UC8TV3Z2lW2B","qrsyDtcnmac8","yJGIyJR2lHGg","2pvQsIXpPaBb"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"EB3dPPlgQeVt","colab_type":"text"},"source":["# Processo de Seleção de Variáveis"]},{"cell_type":"markdown","metadata":{"id":"TsV0SiuwpZ7i","colab_type":"text"},"source":["### Importando libs e funções:"]},{"cell_type":"markdown","metadata":{"id":"k6l8c0olEHpN","colab_type":"text"},"source":["Importando libs"]},{"cell_type":"code","metadata":{"id":"i7FF5Glb_NrK","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import StandardScaler \n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score\n","from matplotlib.colors import ListedColormap\n","from sklearn.linear_model import LinearRegression"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L7RydZ0qEIl4","colab_type":"text"},"source":["Importando funções"]},{"cell_type":"code","metadata":{"id":"KxneBJZUEIz4","colab_type":"code","colab":{}},"source":["# Função de escalonamento\n","def feature_scaling(data):\n","    sc = StandardScaler()\n","    return sc.fit_transform(data)\n","\n","# Função que gera o gráfico dos resultados de regressão\n","def plot_results_linear(X, y, regressor, title):\n","    plt.scatter(X, y, color = 'red')\n","    plt.plot(X, regressor.predict(X), color = 'blue')\n","    plt.title(title)\n","    plt.xlabel('Tamanho do Lote')\n","    plt.ylabel('Preço de Vendas')\n","    plt.show()\n","\n","# Função que gera o gráfico dos resultados de regerssão polinomial\n","def plot_results_poly(X, y, lin_reg_poly, poly_reg, title):\n","    plt.scatter(X, y, color = 'red')\n","    plt.plot(X, lin_reg_poly.predict(poly_reg.fit_transform(X)), color = 'blue')\n","    plt.title(title)\n","    plt.xlabel('Tamanho do Lote')\n","    plt.ylabel('Preço de Vendas')\n","    plt.show()    \n","    \n","# Função que gera o gráfico dos resultados de arvores\n","def plot_results_reg(X, y, regressor, title):     \n","    X_grid = np.arange(min(X), max(X), 0.01)\n","    X_grid = X_grid.reshape((len(X_grid), 1))\n","    plt.scatter(X, y, color = 'red')\n","    plt.plot(X_grid, regressor.predict(X_grid), color = 'blue')\n","    plt.title(title)\n","    plt.xlabel('Tamanho do Lote')\n","    plt.ylabel('Preço de Vendas')\n","    plt.show()\n","     "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QaGBc_KwpeVt","colab_type":"text"},"source":["### Etapa de exploração e tratamento dos **dados**"]},{"cell_type":"markdown","metadata":{"id":"ZfESkLx0EjB8","colab_type":"text"},"source":["Importando o dataset do nosso estudo. O objetivo dos modelos de regressão será de predizer o preço das casas de acordo com diferentes caracteristicas como: localização, área, etc.\n","\n","Fonte: [Kaggle](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)"]},{"cell_type":"code","metadata":{"id":"Yq6eIh3NJnuN","colab_type":"code","colab":{}},"source":["df = pd.read_csv('https://raw.githubusercontent.com/r4phael/ml-course/master/data/pricing_houses.csv')\n","\n","#Selecionando uma amostragem dos dados para uma melhor visualização\n","df = df.loc[:, ['LotArea', 'PoolArea', 'GarageArea', 'OverallCond','YearBuilt', 'MSZoning', 'SalePrice']]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g-LzSHX1Jpg1","colab_type":"text"},"source":["Descrevendo o dataset"]},{"cell_type":"code","metadata":{"id":"hpLEK45DJomb","colab_type":"code","outputId":"571eee12-602e-4fe0-a16d-28dbd632879e","executionInfo":{"status":"ok","timestamp":1574183721959,"user_tz":180,"elapsed":2945,"user":{"displayName":"Jairo Souza","photoUrl":"","userId":"04219546553145172755"}},"colab":{"base_uri":"https://localhost:8080/","height":297}},"source":["df.describe()"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LotArea</th>\n","      <th>PoolArea</th>\n","      <th>GarageArea</th>\n","      <th>OverallCond</th>\n","      <th>YearBuilt</th>\n","      <th>SalePrice</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>1460.000000</td>\n","      <td>1460.000000</td>\n","      <td>1460.000000</td>\n","      <td>1460.000000</td>\n","      <td>1460.000000</td>\n","      <td>1460.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>10516.828082</td>\n","      <td>2.758904</td>\n","      <td>472.980137</td>\n","      <td>5.575342</td>\n","      <td>1971.267808</td>\n","      <td>180921.195890</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>9981.264932</td>\n","      <td>40.177307</td>\n","      <td>213.804841</td>\n","      <td>1.112799</td>\n","      <td>30.202904</td>\n","      <td>79442.502883</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1300.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>1872.000000</td>\n","      <td>34900.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>7553.500000</td>\n","      <td>0.000000</td>\n","      <td>334.500000</td>\n","      <td>5.000000</td>\n","      <td>1954.000000</td>\n","      <td>129975.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>9478.500000</td>\n","      <td>0.000000</td>\n","      <td>480.000000</td>\n","      <td>5.000000</td>\n","      <td>1973.000000</td>\n","      <td>163000.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>11601.500000</td>\n","      <td>0.000000</td>\n","      <td>576.000000</td>\n","      <td>6.000000</td>\n","      <td>2000.000000</td>\n","      <td>214000.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>215245.000000</td>\n","      <td>738.000000</td>\n","      <td>1418.000000</td>\n","      <td>9.000000</td>\n","      <td>2010.000000</td>\n","      <td>755000.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             LotArea     PoolArea  ...    YearBuilt      SalePrice\n","count    1460.000000  1460.000000  ...  1460.000000    1460.000000\n","mean    10516.828082     2.758904  ...  1971.267808  180921.195890\n","std      9981.264932    40.177307  ...    30.202904   79442.502883\n","min      1300.000000     0.000000  ...  1872.000000   34900.000000\n","25%      7553.500000     0.000000  ...  1954.000000  129975.000000\n","50%      9478.500000     0.000000  ...  1973.000000  163000.000000\n","75%     11601.500000     0.000000  ...  2000.000000  214000.000000\n","max    215245.000000   738.000000  ...  2010.000000  755000.000000\n","\n","[8 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"tgh2pe9lJtr6","colab_type":"text"},"source":["Visualizando o dataset"]},{"cell_type":"code","metadata":{"id":"EvY28fJdJxey","colab_type":"code","outputId":"e15b754f-6922-4e55-aecd-8ad2a450671b","executionInfo":{"status":"ok","timestamp":1574183721963,"user_tz":180,"elapsed":2921,"user":{"displayName":"Jairo Souza","photoUrl":"","userId":"04219546553145172755"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["df.head(5)"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LotArea</th>\n","      <th>PoolArea</th>\n","      <th>GarageArea</th>\n","      <th>OverallCond</th>\n","      <th>YearBuilt</th>\n","      <th>MSZoning</th>\n","      <th>SalePrice</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>8450</td>\n","      <td>0</td>\n","      <td>548</td>\n","      <td>5</td>\n","      <td>2003</td>\n","      <td>RL</td>\n","      <td>208500</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9600</td>\n","      <td>0</td>\n","      <td>460</td>\n","      <td>8</td>\n","      <td>1976</td>\n","      <td>RL</td>\n","      <td>181500</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11250</td>\n","      <td>0</td>\n","      <td>608</td>\n","      <td>5</td>\n","      <td>2001</td>\n","      <td>RL</td>\n","      <td>223500</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9550</td>\n","      <td>0</td>\n","      <td>642</td>\n","      <td>5</td>\n","      <td>1915</td>\n","      <td>RL</td>\n","      <td>140000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>14260</td>\n","      <td>0</td>\n","      <td>836</td>\n","      <td>5</td>\n","      <td>2000</td>\n","      <td>RL</td>\n","      <td>250000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   LotArea  PoolArea  GarageArea  OverallCond  YearBuilt MSZoning  SalePrice\n","0     8450         0         548            5       2003       RL     208500\n","1     9600         0         460            8       1976       RL     181500\n","2    11250         0         608            5       2001       RL     223500\n","3     9550         0         642            5       1915       RL     140000\n","4    14260         0         836            5       2000       RL     250000"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"jiMAqVghJylz","colab_type":"text"},"source":["Preenchendo os valores númericos nulos (NA) com a mediana."]},{"cell_type":"code","metadata":{"id":"KFDodNK4JzlR","colab_type":"code","outputId":"2ef14aa2-af36-42a6-bd42-0a8863a5ebda","executionInfo":{"status":"ok","timestamp":1574183721964,"user_tz":180,"elapsed":2826,"user":{"displayName":"Jairo Souza","photoUrl":"","userId":"04219546553145172755"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["df = df.fillna(df.median())\n","\n","df.head(5)"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LotArea</th>\n","      <th>PoolArea</th>\n","      <th>GarageArea</th>\n","      <th>OverallCond</th>\n","      <th>YearBuilt</th>\n","      <th>MSZoning</th>\n","      <th>SalePrice</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>8450</td>\n","      <td>0</td>\n","      <td>548</td>\n","      <td>5</td>\n","      <td>2003</td>\n","      <td>RL</td>\n","      <td>208500</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9600</td>\n","      <td>0</td>\n","      <td>460</td>\n","      <td>8</td>\n","      <td>1976</td>\n","      <td>RL</td>\n","      <td>181500</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11250</td>\n","      <td>0</td>\n","      <td>608</td>\n","      <td>5</td>\n","      <td>2001</td>\n","      <td>RL</td>\n","      <td>223500</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9550</td>\n","      <td>0</td>\n","      <td>642</td>\n","      <td>5</td>\n","      <td>1915</td>\n","      <td>RL</td>\n","      <td>140000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>14260</td>\n","      <td>0</td>\n","      <td>836</td>\n","      <td>5</td>\n","      <td>2000</td>\n","      <td>RL</td>\n","      <td>250000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   LotArea  PoolArea  GarageArea  OverallCond  YearBuilt MSZoning  SalePrice\n","0     8450         0         548            5       2003       RL     208500\n","1     9600         0         460            8       1976       RL     181500\n","2    11250         0         608            5       2001       RL     223500\n","3     9550         0         642            5       1915       RL     140000\n","4    14260         0         836            5       2000       RL     250000"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"jXWksGyoJ0u3","colab_type":"text"},"source":["Definindo as variáveis independentes e dependentes"]},{"cell_type":"code","metadata":{"id":"lJ0y3JijJ1ii","colab_type":"code","colab":{}},"source":["X = df.loc[:, 'LotArea'].values.reshape(-1,1)\n","y = df.loc[:, 'SalePrice'].values.reshape(-1,1)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"UC8TV3Z2lW2B"},"source":["## Forward Elimination\n"]},{"cell_type":"markdown","metadata":{"id":"cPd_vjDamxMl","colab_type":"text"},"source":["### Etapa de Seleção e Tratamento dos Dados"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"aoDXtcm5lW2F"},"source":["No processo de Forward Elimination, iremos selecionar as features incrementalmente uma por uma e analisamos se a mesma contribui para a melhoria do modelo. Porsteriormente, treinamos o modelo com a package OLS que realiza o processo de cálculo dos coeficientes para analise:"]},{"cell_type":"markdown","metadata":{"id":"8EnNPQl1pS7L","colab_type":"text"},"source":["Selecionando a primeira feature: *LotArea*"]},{"cell_type":"code","metadata":{"id":"4EKrDJHWpRrO","colab_type":"code","outputId":"24098239-aad6-454e-c8eb-4d40079491e6","executionInfo":{"status":"ok","timestamp":1574183721966,"user_tz":180,"elapsed":2781,"user":{"displayName":"Jairo Souza","photoUrl":"","userId":"04219546553145172755"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["df_forward = df.loc[:,['LotArea', 'SalePrice']]\n","\n","df_forward.head(5)"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LotArea</th>\n","      <th>SalePrice</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>8450</td>\n","      <td>208500</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9600</td>\n","      <td>181500</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11250</td>\n","      <td>223500</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9550</td>\n","      <td>140000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>14260</td>\n","      <td>250000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   LotArea  SalePrice\n","0     8450     208500\n","1     9600     181500\n","2    11250     223500\n","3     9550     140000\n","4    14260     250000"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"d_AaV4oLm6G7","colab_type":"text"},"source":["### Realizando o Processo de Foward Elimination\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"JEP6wygGlW2C"},"source":["Realizando o processo de forward elimination. Primeiro, será inserido uma coluna preenchida com valores 1 no começo da matriz de variáveis. Isso é realizada para que sejam feito os calculos necessários:"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"81b46b34-0b20-4c5b-9741-ef93f5ac76f8","executionInfo":{"status":"ok","timestamp":1574183721967,"user_tz":180,"elapsed":2750,"user":{"displayName":"Jairo Souza","photoUrl":"","userId":"04219546553145172755"}},"id":"g7fedOQflW2C","colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["X = np.append(arr = np.ones((1460,1)).astype(int), values = df_forward, axis =1)\n","\n","X[1:5,:]\n"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[     1,   9600, 181500],\n","       [     1,  11250, 223500],\n","       [     1,   9550, 140000],\n","       [     1,  14260, 250000]])"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"Bl0mXWMHsGO8","colab_type":"text"},"source":["Após isso, será utilizada a package OLS para calculo de importancia das features no output do modelo:"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"82dc2ce6-73e2-42ef-9d47-8f7caeb3ab15","executionInfo":{"status":"ok","timestamp":1574183816951,"user_tz":180,"elapsed":1157,"user":{"displayName":"Jairo Souza","photoUrl":"","userId":"04219546553145172755"}},"id":"BUh57AsOlW2F","colab":{"base_uri":"https://localhost:8080/","height":478}},"source":["# Importando a package.\n","import statsmodels.regression.linear_model as sm\n","\n","X_opt = X[:, [0,1]]\n","regressor_ols = sm.OLS(endog = y, exog = X[:, [0,1]]).fit()\n","regressor_ols.summary()"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/html":["<table class=\"simpletable\">\n","<caption>OLS Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.070</td> \n","</tr>\n","<tr>\n","  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.069</td> \n","</tr>\n","<tr>\n","  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   109.1</td> \n","</tr>\n","<tr>\n","  <th>Date:</th>             <td>Tue, 19 Nov 2019</td> <th>  Prob (F-statistic):</th> <td>1.12e-24</td> \n","</tr>\n","<tr>\n","  <th>Time:</th>                 <td>17:17:08</td>     <th>  Log-Likelihood:    </th> <td> -18491.</td> \n","</tr>\n","<tr>\n","  <th>No. Observations:</th>      <td>  1460</td>      <th>  AIC:               </th> <td>3.699e+04</td>\n","</tr>\n","<tr>\n","  <th>Df Residuals:</th>          <td>  1458</td>      <th>  BIC:               </th> <td>3.700e+04</td>\n","</tr>\n","<tr>\n","  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>const</th> <td> 1.588e+05</td> <td> 2914.717</td> <td>   54.495</td> <td> 0.000</td> <td> 1.53e+05</td> <td> 1.65e+05</td>\n","</tr>\n","<tr>\n","  <th>x1</th>    <td>    2.1000</td> <td>    0.201</td> <td>   10.445</td> <td> 0.000</td> <td>    1.706</td> <td>    2.494</td>\n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","  <th>Omnibus:</th>       <td>587.660</td> <th>  Durbin-Watson:     </th> <td>   1.998</td>\n","</tr>\n","<tr>\n","  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3374.003</td>\n","</tr>\n","<tr>\n","  <th>Skew:</th>          <td> 1.788</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n","</tr>\n","<tr>\n","  <th>Kurtosis:</th>      <td> 9.532</td>  <th>  Cond. No.          </th> <td>2.11e+04</td>\n","</tr>\n","</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.11e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."],"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                      y   R-squared:                       0.070\n","Model:                            OLS   Adj. R-squared:                  0.069\n","Method:                 Least Squares   F-statistic:                     109.1\n","Date:                Tue, 19 Nov 2019   Prob (F-statistic):           1.12e-24\n","Time:                        17:17:08   Log-Likelihood:                -18491.\n","No. Observations:                1460   AIC:                         3.699e+04\n","Df Residuals:                    1458   BIC:                         3.700e+04\n","Df Model:                           1                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","const       1.588e+05   2914.717     54.495      0.000    1.53e+05    1.65e+05\n","x1             2.1000      0.201     10.445      0.000       1.706       2.494\n","==============================================================================\n","Omnibus:                      587.660   Durbin-Watson:                   1.998\n","Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3374.003\n","Skew:                           1.788   Prob(JB):                         0.00\n","Kurtosis:                       9.532   Cond. No.                     2.11e+04\n","==============================================================================\n","\n","Warnings:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","[2] The condition number is large, 2.11e+04. This might indicate that there are\n","strong multicollinearity or other numerical problems.\n","\"\"\""]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"U-RSW_bQlW2I"},"source":["Analisando os valores acima, vimos que as features X1(*LotArea* - Área do lote) possui um P-value significativo, ou seja, dentro do level de signifcância definida (SL = .05) .Portanto, deixamos a mesma e escolhemos outra feature para incrementar no modelo conforme o processo de Forward Elimination.  \n","\n","**Obs: Definimos um level de significância de .05 para que as features permaneçam no modelo (SL = .05).**"]},{"cell_type":"markdown","metadata":{"id":"-uj0bMeNrIWv","colab_type":"text"},"source":["Adicionando a segunda feature no dataframe"]},{"cell_type":"code","metadata":{"id":"8fLhVreGrIfr","colab_type":"code","outputId":"6c3356b0-af3c-4a2c-f3d7-8b3cacf2aaba","executionInfo":{"status":"ok","timestamp":1574183844540,"user_tz":180,"elapsed":874,"user":{"displayName":"Jairo Souza","photoUrl":"","userId":"04219546553145172755"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["df_forward = pd.concat([df_forward, df['GarageArea']], axis=1)\n","\n","df_forward.head(5)"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LotArea</th>\n","      <th>SalePrice</th>\n","      <th>GarageArea</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>8450</td>\n","      <td>208500</td>\n","      <td>548</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9600</td>\n","      <td>181500</td>\n","      <td>460</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11250</td>\n","      <td>223500</td>\n","      <td>608</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9550</td>\n","      <td>140000</td>\n","      <td>642</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>14260</td>\n","      <td>250000</td>\n","      <td>836</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   LotArea  SalePrice  GarageArea\n","0     8450     208500         548\n","1     9600     181500         460\n","2    11250     223500         608\n","3     9550     140000         642\n","4    14260     250000         836"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"drqbur2qsCJv","colab_type":"text"},"source":["Calculando os coeficientes com a segunda features:"]},{"cell_type":"code","metadata":{"id":"aCAhwA5nsCSc","colab_type":"code","outputId":"56986131-54fa-4cd4-fedb-80b7b161724b","executionInfo":{"status":"ok","timestamp":1574183847912,"user_tz":180,"elapsed":935,"user":{"displayName":"Jairo Souza","photoUrl":"","userId":"04219546553145172755"}},"colab":{"base_uri":"https://localhost:8080/","height":499}},"source":["\n","# Adicionando 1 na primeira coluna da matriz de features \n","X = np.append(arr = np.ones((1460,1)).astype(int), values = df_forward, axis =1)\n","\n","# Selecionando apenas as features de indice 0-const, 1-SalesPrice, 3-GarageArea\n","X_opt = X[:, [0,1,3]]\n","regressor_ols = sm.OLS(endog = y, exog = X_opt).fit()\n","regressor_ols.summary()"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/html":["<table class=\"simpletable\">\n","<caption>OLS Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.412</td> \n","</tr>\n","<tr>\n","  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.412</td> \n","</tr>\n","<tr>\n","  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   511.2</td> \n","</tr>\n","<tr>\n","  <th>Date:</th>             <td>Tue, 19 Nov 2019</td> <th>  Prob (F-statistic):</th> <td>6.34e-169</td>\n","</tr>\n","<tr>\n","  <th>Time:</th>                 <td>17:17:39</td>     <th>  Log-Likelihood:    </th> <td> -18156.</td> \n","</tr>\n","<tr>\n","  <th>No. Observations:</th>      <td>  1460</td>      <th>  AIC:               </th> <td>3.632e+04</td>\n","</tr>\n","<tr>\n","  <th>Df Residuals:</th>          <td>  1457</td>      <th>  BIC:               </th> <td>3.633e+04</td>\n","</tr>\n","<tr>\n","  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>const</th> <td> 6.322e+04</td> <td> 4015.973</td> <td>   15.742</td> <td> 0.000</td> <td> 5.53e+04</td> <td> 7.11e+04</td>\n","</tr>\n","<tr>\n","  <th>x1</th>    <td>    1.2453</td> <td>    0.163</td> <td>    7.663</td> <td> 0.000</td> <td>    0.927</td> <td>    1.564</td>\n","</tr>\n","<tr>\n","  <th>x2</th>    <td>  221.1574</td> <td>    7.587</td> <td>   29.151</td> <td> 0.000</td> <td>  206.276</td> <td>  236.039</td>\n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","  <th>Omnibus:</th>       <td>544.830</td> <th>  Durbin-Watson:     </th> <td>   2.023</td>\n","</tr>\n","<tr>\n","  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5456.748</td>\n","</tr>\n","<tr>\n","  <th>Skew:</th>          <td> 1.446</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n","</tr>\n","<tr>\n","  <th>Kurtosis:</th>      <td>12.018</td>  <th>  Cond. No.          </th> <td>3.65e+04</td>\n","</tr>\n","</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.65e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."],"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                      y   R-squared:                       0.412\n","Model:                            OLS   Adj. R-squared:                  0.412\n","Method:                 Least Squares   F-statistic:                     511.2\n","Date:                Tue, 19 Nov 2019   Prob (F-statistic):          6.34e-169\n","Time:                        17:17:39   Log-Likelihood:                -18156.\n","No. Observations:                1460   AIC:                         3.632e+04\n","Df Residuals:                    1457   BIC:                         3.633e+04\n","Df Model:                           2                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","const       6.322e+04   4015.973     15.742      0.000    5.53e+04    7.11e+04\n","x1             1.2453      0.163      7.663      0.000       0.927       1.564\n","x2           221.1574      7.587     29.151      0.000     206.276     236.039\n","==============================================================================\n","Omnibus:                      544.830   Durbin-Watson:                   2.023\n","Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5456.748\n","Skew:                           1.446   Prob(JB):                         0.00\n","Kurtosis:                      12.018   Cond. No.                     3.65e+04\n","==============================================================================\n","\n","Warnings:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","[2] The condition number is large, 3.65e+04. This might indicate that there are\n","strong multicollinearity or other numerical problems.\n","\"\"\""]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jp5B6RySlW2L"},"source":["**Final:** Todas as features acima estão dentro dentro intervalo de significância do modelo (SL = .05). Portanto, o processo continua de maneira incremental até que o modelo não seja improvisado com a adição de novas features."]},{"cell_type":"markdown","metadata":{"id":"fnB83_TCtkqm","colab_type":"text"},"source":["Calculando o score do modelo:"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"d122caef-64f8-4dd1-90b6-7d3452381a97","executionInfo":{"status":"ok","timestamp":1574183893672,"user_tz":180,"elapsed":1019,"user":{"displayName":"Jairo Souza","photoUrl":"","userId":"04219546553145172755"}},"id":"kip24crWlW2M","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["regressor = LinearRegression()\n","regressor.fit(X_opt, y)"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_THRIQTQlW2Q"},"source":["Analisando o novo score do modelo com a métrica r2"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"0dc95339-f8a8-4a43-8407-0d3a0092c761","executionInfo":{"status":"ok","timestamp":1574183896608,"user_tz":180,"elapsed":876,"user":{"displayName":"Jairo Souza","photoUrl":"","userId":"04219546553145172755"}},"id":"6O_eCKVglW2R","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["regressor.score(X_opt, y)"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.41235186539832547"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qrsyDtcnmac8"},"source":["##  Backward Elimination"]},{"cell_type":"markdown","metadata":{"id":"yJGIyJR2lHGg","colab_type":"text"},"source":["### Etapa de Seleção e Tratamento dos Dados"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"OOp4xvgvmac_"},"source":["Selecionando as principais features do dataset:"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"8e24dd43-1ccb-482d-8e8a-2f36003db99c","executionInfo":{"status":"ok","timestamp":1574183902868,"user_tz":180,"elapsed":892,"user":{"displayName":"Jairo Souza","photoUrl":"","userId":"04219546553145172755"}},"id":"cBeGPIi8madA","colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["df = df.loc[:, ['LotArea', 'PoolArea', 'GarageArea', 'YearBuilt', 'SalePrice']]\n","\n","df.head(5)"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LotArea</th>\n","      <th>PoolArea</th>\n","      <th>GarageArea</th>\n","      <th>YearBuilt</th>\n","      <th>SalePrice</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>8450</td>\n","      <td>0</td>\n","      <td>548</td>\n","      <td>2003</td>\n","      <td>208500</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9600</td>\n","      <td>0</td>\n","      <td>460</td>\n","      <td>1976</td>\n","      <td>181500</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11250</td>\n","      <td>0</td>\n","      <td>608</td>\n","      <td>2001</td>\n","      <td>223500</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9550</td>\n","      <td>0</td>\n","      <td>642</td>\n","      <td>1915</td>\n","      <td>140000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>14260</td>\n","      <td>0</td>\n","      <td>836</td>\n","      <td>2000</td>\n","      <td>250000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   LotArea  PoolArea  GarageArea  YearBuilt  SalePrice\n","0     8450         0         548       2003     208500\n","1     9600         0         460       1976     181500\n","2    11250         0         608       2001     223500\n","3     9550         0         642       1915     140000\n","4    14260         0         836       2000     250000"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kDYdDj9YmadI"},"source":["Definindo as variáveis indepedentes e dependentes, normalição das features e dividisão do dataset em conjunto de treinamento e testes:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YA4W7LqwmadJ","colab":{}},"source":["X = df[df.columns[~df.columns.isin(['SalePrice'])]].values\n","y = df['SalePrice'].values.reshape(-1,1)\n","\n","# Normalização das features:\n","X = feature_scaling(X)\n","\n","# Dividindo os dados\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XKpYcfrgvh04"},"source":["### Realizando o Processo de Backward Elimination\n"]},{"cell_type":"markdown","metadata":{"id":"YO6tuntUcdRT","colab_type":"text"},"source":["Realizando o processo de backward elimination. Primeiro, será inserido uma coluna preenchida com valores 1 no começo da matriz de variáveis. Isso é realizada para que sejam feito os calculos necessários:"]},{"cell_type":"code","metadata":{"id":"6SRDaFyZc3Zp","colab_type":"code","outputId":"ad7c7e62-8664-439c-876c-9c6fc3715c22","executionInfo":{"status":"ok","timestamp":1574183913243,"user_tz":180,"elapsed":1120,"user":{"displayName":"Jairo Souza","photoUrl":"","userId":"04219546553145172755"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["X_train = np.append(arr = np.ones((1168,1)).astype(int), values = X_train, axis =1)\n","\n","X_train[2,:]\n"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 1.        , -0.1743691 , -0.06869175, -2.21296298, -2.02923537])"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"DCA2FS2pdP9B","colab_type":"text"},"source":["Selecionando as variáveis do conjunto de treinamento e treinando o modelo com a package OLS que realiza o processo de cálculo dos coeficientes para analise:"]},{"cell_type":"code","metadata":{"id":"y7CxxtISwwSf","colab_type":"code","outputId":"1feada30-0da3-450e-d2c9-715cbe55f5f7","executionInfo":{"status":"ok","timestamp":1574183918334,"user_tz":180,"elapsed":1390,"user":{"displayName":"Jairo Souza","photoUrl":"","userId":"04219546553145172755"}},"colab":{"base_uri":"https://localhost:8080/","height":507}},"source":["# Importando a package.\n","import statsmodels.regression.linear_model as sm\n","\n","X_opt = X_train[:, [0,1,2,3,4]]\n","regressor_ols = sm.OLS(endog = y_train, exog = X_opt).fit()\n","regressor_ols.summary()"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/html":["<table class=\"simpletable\">\n","<caption>OLS Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.490</td> \n","</tr>\n","<tr>\n","  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.488</td> \n","</tr>\n","<tr>\n","  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   279.4</td> \n","</tr>\n","<tr>\n","  <th>Date:</th>             <td>Tue, 19 Nov 2019</td> <th>  Prob (F-statistic):</th> <td>2.31e-168</td>\n","</tr>\n","<tr>\n","  <th>Time:</th>                 <td>17:18:49</td>     <th>  Log-Likelihood:    </th> <td> -14409.</td> \n","</tr>\n","<tr>\n","  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.883e+04</td>\n","</tr>\n","<tr>\n","  <th>Df Residuals:</th>          <td>  1163</td>      <th>  BIC:               </th> <td>2.885e+04</td>\n","</tr>\n","<tr>\n","  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>const</th> <td> 1.809e+05</td> <td> 1617.751</td> <td>  111.820</td> <td> 0.000</td> <td> 1.78e+05</td> <td> 1.84e+05</td>\n","</tr>\n","<tr>\n","  <th>x1</th>    <td> 1.268e+04</td> <td> 1533.794</td> <td>    8.267</td> <td> 0.000</td> <td> 9670.830</td> <td> 1.57e+04</td>\n","</tr>\n","<tr>\n","  <th>x2</th>    <td> 4729.7608</td> <td> 1570.186</td> <td>    3.012</td> <td> 0.003</td> <td> 1649.047</td> <td> 7810.475</td>\n","</tr>\n","<tr>\n","  <th>x3</th>    <td> 3.476e+04</td> <td> 1893.434</td> <td>   18.359</td> <td> 0.000</td> <td>  3.1e+04</td> <td> 3.85e+04</td>\n","</tr>\n","<tr>\n","  <th>x4</th>    <td> 2.331e+04</td> <td> 1807.127</td> <td>   12.897</td> <td> 0.000</td> <td> 1.98e+04</td> <td> 2.69e+04</td>\n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","  <th>Omnibus:</th>       <td>435.926</td> <th>  Durbin-Watson:     </th> <td>   2.015</td>\n","</tr>\n","<tr>\n","  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3360.331</td>\n","</tr>\n","<tr>\n","  <th>Skew:</th>          <td> 1.517</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n","</tr>\n","<tr>\n","  <th>Kurtosis:</th>      <td>10.736</td>  <th>  Cond. No.          </th> <td>    1.75</td>\n","</tr>\n","</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."],"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                      y   R-squared:                       0.490\n","Model:                            OLS   Adj. R-squared:                  0.488\n","Method:                 Least Squares   F-statistic:                     279.4\n","Date:                Tue, 19 Nov 2019   Prob (F-statistic):          2.31e-168\n","Time:                        17:18:49   Log-Likelihood:                -14409.\n","No. Observations:                1168   AIC:                         2.883e+04\n","Df Residuals:                    1163   BIC:                         2.885e+04\n","Df Model:                           4                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","const       1.809e+05   1617.751    111.820      0.000    1.78e+05    1.84e+05\n","x1          1.268e+04   1533.794      8.267      0.000    9670.830    1.57e+04\n","x2          4729.7608   1570.186      3.012      0.003    1649.047    7810.475\n","x3          3.476e+04   1893.434     18.359      0.000     3.1e+04    3.85e+04\n","x4          2.331e+04   1807.127     12.897      0.000    1.98e+04    2.69e+04\n","==============================================================================\n","Omnibus:                      435.926   Durbin-Watson:                   2.015\n","Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3360.331\n","Skew:                           1.517   Prob(JB):                         0.00\n","Kurtosis:                      10.736   Cond. No.                         1.75\n","==============================================================================\n","\n","Warnings:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","\"\"\""]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"markdown","metadata":{"id":"vaUpqWO2dgT2","colab_type":"text"},"source":["Analisando os valores acima, vimos que a feature X2 (*PoolArea* - Área da piscina) possui o menor grau de importância, ou seja, o maior P-value, já que possui um p-value de .003, equanto as outras features possui um valor abaixo de .000 .Portanto, removemos a mesma e reiniciamos o processo conforme o algoritmo de Backward Elimination.  \n","\n","**Obs: Definimos um level de significância de .03 nesse caso específico como exemplo para que as features permaneçam no modelo (SL = .05).**"]},{"cell_type":"code","metadata":{"id":"SUUM2LlRgdSP","colab_type":"code","outputId":"e3cbbd13-2369-4b7e-c79f-95a6c78c2ff6","executionInfo":{"status":"ok","timestamp":1574183918336,"user_tz":180,"elapsed":1310,"user":{"displayName":"Jairo Souza","photoUrl":"","userId":"04219546553145172755"}},"colab":{"base_uri":"https://localhost:8080/","height":486}},"source":["#Analisando todas as features, exceto a feature X2 (Índice 1)\n","\n","X_opt = X_train[:, [0,2,3,4]]\n","regressor_ols = sm.OLS(endog = y_train, exog = X_opt).fit()\n","regressor_ols.summary()"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/html":["<table class=\"simpletable\">\n","<caption>OLS Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.460</td> \n","</tr>\n","<tr>\n","  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.459</td> \n","</tr>\n","<tr>\n","  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   330.7</td> \n","</tr>\n","<tr>\n","  <th>Date:</th>             <td>Tue, 19 Nov 2019</td> <th>  Prob (F-statistic):</th> <td>2.90e-155</td>\n","</tr>\n","<tr>\n","  <th>Time:</th>                 <td>17:18:50</td>     <th>  Log-Likelihood:    </th> <td> -14443.</td> \n","</tr>\n","<tr>\n","  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.889e+04</td>\n","</tr>\n","<tr>\n","  <th>Df Residuals:</th>          <td>  1164</td>      <th>  BIC:               </th> <td>2.891e+04</td>\n","</tr>\n","<tr>\n","  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>const</th> <td> 1.811e+05</td> <td> 1663.777</td> <td>  108.821</td> <td> 0.000</td> <td> 1.78e+05</td> <td> 1.84e+05</td>\n","</tr>\n","<tr>\n","  <th>x1</th>    <td> 5649.3615</td> <td> 1610.913</td> <td>    3.507</td> <td> 0.000</td> <td> 2488.743</td> <td> 8809.980</td>\n","</tr>\n","<tr>\n","  <th>x2</th>    <td> 3.772e+04</td> <td> 1912.254</td> <td>   19.727</td> <td> 0.000</td> <td>  3.4e+04</td> <td> 4.15e+04</td>\n","</tr>\n","<tr>\n","  <th>x3</th>    <td> 2.214e+04</td> <td> 1853.006</td> <td>   11.949</td> <td> 0.000</td> <td> 1.85e+04</td> <td> 2.58e+04</td>\n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","  <th>Omnibus:</th>       <td>441.037</td> <th>  Durbin-Watson:     </th> <td>   1.983</td>\n","</tr>\n","<tr>\n","  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2831.186</td>\n","</tr>\n","<tr>\n","  <th>Skew:</th>          <td> 1.602</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n","</tr>\n","<tr>\n","  <th>Kurtosis:</th>      <td> 9.922</td>  <th>  Cond. No.          </th> <td>    1.67</td>\n","</tr>\n","</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."],"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                      y   R-squared:                       0.460\n","Model:                            OLS   Adj. R-squared:                  0.459\n","Method:                 Least Squares   F-statistic:                     330.7\n","Date:                Tue, 19 Nov 2019   Prob (F-statistic):          2.90e-155\n","Time:                        17:18:50   Log-Likelihood:                -14443.\n","No. Observations:                1168   AIC:                         2.889e+04\n","Df Residuals:                    1164   BIC:                         2.891e+04\n","Df Model:                           3                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","const       1.811e+05   1663.777    108.821      0.000    1.78e+05    1.84e+05\n","x1          5649.3615   1610.913      3.507      0.000    2488.743    8809.980\n","x2          3.772e+04   1912.254     19.727      0.000     3.4e+04    4.15e+04\n","x3          2.214e+04   1853.006     11.949      0.000    1.85e+04    2.58e+04\n","==============================================================================\n","Omnibus:                      441.037   Durbin-Watson:                   1.983\n","Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2831.186\n","Skew:                           1.602   Prob(JB):                         0.00\n","Kurtosis:                       9.922   Cond. No.                         1.67\n","==============================================================================\n","\n","Warnings:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","\"\"\""]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"markdown","metadata":{"id":"xJp_hnTkim6o","colab_type":"text"},"source":["**Final:** Todas as features acima estão dentro dentro intervalo de significância do modelo (SL = .05). Portanto, o processo é finalizado e seguimos para o treinamento do modelo."]},{"cell_type":"code","metadata":{"id":"_q6TLZini8iZ","colab_type":"code","outputId":"27d90cb6-29ab-4be2-93b7-184133e0f726","executionInfo":{"status":"ok","timestamp":1574183918339,"user_tz":180,"elapsed":1288,"user":{"displayName":"Jairo Souza","photoUrl":"","userId":"04219546553145172755"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["regressor = LinearRegression()\n","regressor.fit(X_opt, y_train)"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"z4-ETswtkaLF","colab_type":"text"},"source":["Analisando o novo score do modelo com a métrica r2"]},{"cell_type":"code","metadata":{"id":"FGVjEh5jkaUj","colab_type":"code","outputId":"4a5e6a71-8b29-4607-8c9b-d57fca467bf8","executionInfo":{"status":"ok","timestamp":1574183918341,"user_tz":180,"elapsed":1268,"user":{"displayName":"Jairo Souza","photoUrl":"","userId":"04219546553145172755"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["regressor.score(X_test, y_test)"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4484569043113157"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2pvQsIXpPaBb"},"source":["##  Bidirectional Elimination"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0KLvLtBJfSY_"},"source":["### Etapa de Seleção e Tratamento dos Dados"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jy6iIEI9fSZC"},"source":["Selecionando as principais features do dataset:"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"d149b851-9334-4cfc-8f58-dc451ed73519","executionInfo":{"status":"ok","timestamp":1574183918342,"user_tz":180,"elapsed":1248,"user":{"displayName":"Jairo Souza","photoUrl":"","userId":"04219546553145172755"}},"id":"rFF2Y7dDfSZC","colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["df = df.loc[:, ['LotArea', 'PoolArea', 'GarageArea', 'YearBuilt', 'SalePrice']]\n","\n","df.head(5)"],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LotArea</th>\n","      <th>PoolArea</th>\n","      <th>GarageArea</th>\n","      <th>YearBuilt</th>\n","      <th>SalePrice</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>8450</td>\n","      <td>0</td>\n","      <td>548</td>\n","      <td>2003</td>\n","      <td>208500</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9600</td>\n","      <td>0</td>\n","      <td>460</td>\n","      <td>1976</td>\n","      <td>181500</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11250</td>\n","      <td>0</td>\n","      <td>608</td>\n","      <td>2001</td>\n","      <td>223500</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9550</td>\n","      <td>0</td>\n","      <td>642</td>\n","      <td>1915</td>\n","      <td>140000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>14260</td>\n","      <td>0</td>\n","      <td>836</td>\n","      <td>2000</td>\n","      <td>250000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   LotArea  PoolArea  GarageArea  YearBuilt  SalePrice\n","0     8450         0         548       2003     208500\n","1     9600         0         460       1976     181500\n","2    11250         0         608       2001     223500\n","3     9550         0         642       1915     140000\n","4    14260         0         836       2000     250000"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hIW_O9nxfSZG"},"source":["Definindo as variáveis indepedentes e dependentes, normalição das features e dividisão do dataset em conjunto de treinamento e testes:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SMFz-xq_fSZH","colab":{}},"source":["X = df[df.columns[~df.columns.isin(['SalePrice'])]].values\n","y = df['SalePrice'].values.reshape(-1,1)\n","\n","# Normalização das features:\n","X = feature_scaling(X)\n","\n","# Dividindo os dados\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"uo1NZWD_PaB0"},"source":["### Realizando o Processo de Bidirectional Elimination\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"FSHL4ejUPaB2"},"source":["Realizando o processo de Bidirectional elimination que é essencialmente um procedimento de Foward Elminiation, porém com a possibilidade de excluir uma variável selecionada em cada etapa como na  Backward Elimination, quando não há melhoria no modelo. Portanto, o processo é executado adicionando/removendo variáveis baseados em um critério especifico definido pelo usuário (p-values no nosso caso)."]},{"cell_type":"markdown","metadata":{"id":"klIJA30Rafk_","colab_type":"text"},"source":["Primeiro, será adicionado uma variável constante como pré-requisito para execução dos procedimentos."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tJraZaWkPaB3","colab":{}},"source":["X_train = np.append(arr = np.ones((1168,1)).astype(int), values = X_train, axis =1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9PD31Tc_axrl","colab_type":"text"},"source":["Analisando as features da nossa matrix: 0 - Constante, 1 - LotArea, 2 - PoolArea, 3 - GarageArea, 4 - OverallCond, 5 - YearBuilt."]},{"cell_type":"code","metadata":{"id":"i3BrYjaVax3t","colab_type":"code","outputId":"454f8d89-ba14-4987-a423-519a6340057e","executionInfo":{"status":"ok","timestamp":1574183918717,"user_tz":180,"elapsed":1581,"user":{"displayName":"Jairo Souza","photoUrl":"","userId":"04219546553145172755"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["np.shape(X_train)"],"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1168, 5)"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HgHRrYNKPaB6"},"source":["Selecionando as variáveis do conjunto de treinamento e treinando o modelo com a package OLS que realiza o processo de cálculo dos coeficientes para analise:"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"99bcf50c-fc46-4da8-b5b7-b09917a089b4","executionInfo":{"status":"ok","timestamp":1574183918719,"user_tz":180,"elapsed":1570,"user":{"displayName":"Jairo Souza","photoUrl":"","userId":"04219546553145172755"}},"id":"dP5iSVd2PaB7","colab":{"base_uri":"https://localhost:8080/","height":507}},"source":["# Importando a package.\n","import statsmodels.regression.linear_model as sm\n","\n","# Escolhendo algumas Features \n","X_opt = X_train[:, [0,1,2,3,4]]\n","regressor_ols = sm.OLS(endog = y_train, exog = X_opt).fit()\n","regressor_ols.summary()"],"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/html":["<table class=\"simpletable\">\n","<caption>OLS Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.490</td> \n","</tr>\n","<tr>\n","  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.488</td> \n","</tr>\n","<tr>\n","  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   279.4</td> \n","</tr>\n","<tr>\n","  <th>Date:</th>             <td>Tue, 19 Nov 2019</td> <th>  Prob (F-statistic):</th> <td>2.31e-168</td>\n","</tr>\n","<tr>\n","  <th>Time:</th>                 <td>17:18:50</td>     <th>  Log-Likelihood:    </th> <td> -14409.</td> \n","</tr>\n","<tr>\n","  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.883e+04</td>\n","</tr>\n","<tr>\n","  <th>Df Residuals:</th>          <td>  1163</td>      <th>  BIC:               </th> <td>2.885e+04</td>\n","</tr>\n","<tr>\n","  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>const</th> <td> 1.809e+05</td> <td> 1617.751</td> <td>  111.820</td> <td> 0.000</td> <td> 1.78e+05</td> <td> 1.84e+05</td>\n","</tr>\n","<tr>\n","  <th>x1</th>    <td> 1.268e+04</td> <td> 1533.794</td> <td>    8.267</td> <td> 0.000</td> <td> 9670.830</td> <td> 1.57e+04</td>\n","</tr>\n","<tr>\n","  <th>x2</th>    <td> 4729.7608</td> <td> 1570.186</td> <td>    3.012</td> <td> 0.003</td> <td> 1649.047</td> <td> 7810.475</td>\n","</tr>\n","<tr>\n","  <th>x3</th>    <td> 3.476e+04</td> <td> 1893.434</td> <td>   18.359</td> <td> 0.000</td> <td>  3.1e+04</td> <td> 3.85e+04</td>\n","</tr>\n","<tr>\n","  <th>x4</th>    <td> 2.331e+04</td> <td> 1807.127</td> <td>   12.897</td> <td> 0.000</td> <td> 1.98e+04</td> <td> 2.69e+04</td>\n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","  <th>Omnibus:</th>       <td>435.926</td> <th>  Durbin-Watson:     </th> <td>   2.015</td>\n","</tr>\n","<tr>\n","  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3360.331</td>\n","</tr>\n","<tr>\n","  <th>Skew:</th>          <td> 1.517</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n","</tr>\n","<tr>\n","  <th>Kurtosis:</th>      <td>10.736</td>  <th>  Cond. No.          </th> <td>    1.75</td>\n","</tr>\n","</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."],"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                      y   R-squared:                       0.490\n","Model:                            OLS   Adj. R-squared:                  0.488\n","Method:                 Least Squares   F-statistic:                     279.4\n","Date:                Tue, 19 Nov 2019   Prob (F-statistic):          2.31e-168\n","Time:                        17:18:50   Log-Likelihood:                -14409.\n","No. Observations:                1168   AIC:                         2.883e+04\n","Df Residuals:                    1163   BIC:                         2.885e+04\n","Df Model:                           4                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","const       1.809e+05   1617.751    111.820      0.000    1.78e+05    1.84e+05\n","x1          1.268e+04   1533.794      8.267      0.000    9670.830    1.57e+04\n","x2          4729.7608   1570.186      3.012      0.003    1649.047    7810.475\n","x3          3.476e+04   1893.434     18.359      0.000     3.1e+04    3.85e+04\n","x4          2.331e+04   1807.127     12.897      0.000    1.98e+04    2.69e+04\n","==============================================================================\n","Omnibus:                      435.926   Durbin-Watson:                   2.015\n","Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3360.331\n","Skew:                           1.517   Prob(JB):                         0.00\n","Kurtosis:                      10.736   Cond. No.                         1.75\n","==============================================================================\n","\n","Warnings:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","\"\"\""]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"K13KU18lPaCA"},"source":["Analisando os valores acima, vimos que a feature X2 (*PoolArea* - Área da piscina) possui o menor grau de importância, ou seja, um P-value acima do threshold, já que possui um p-value de .003, equanto as outras features possui um valor abaixo de .001 .\n","\n","Portanto, removemos essas features conforme o procedimento padrão. Porém, também iremos também adicionar as features restantes conforme o processo de Bidirectional Elimination.\n","\n","**Obs: Definimos um level de significância de .05 para que as features permaneçam no modelo (SL = .03).**"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"0ad0d0da-8e68-447c-8e22-5970939bf4ad","executionInfo":{"status":"ok","timestamp":1574183918724,"user_tz":180,"elapsed":1562,"user":{"displayName":"Jairo Souza","photoUrl":"","userId":"04219546553145172755"}},"id":"YujYN0YQPaCC","colab":{"base_uri":"https://localhost:8080/","height":486}},"source":["#Analisando todas as features, exceto a feature X2 (Índice 1)\n","\n","X_opt = X_train[:, [0,2,3,4]]\n","regressor_ols = sm.OLS(endog = y_train, exog = X_opt).fit()\n","regressor_ols.summary()"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/html":["<table class=\"simpletable\">\n","<caption>OLS Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.460</td> \n","</tr>\n","<tr>\n","  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.459</td> \n","</tr>\n","<tr>\n","  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   330.7</td> \n","</tr>\n","<tr>\n","  <th>Date:</th>             <td>Tue, 19 Nov 2019</td> <th>  Prob (F-statistic):</th> <td>2.90e-155</td>\n","</tr>\n","<tr>\n","  <th>Time:</th>                 <td>17:18:50</td>     <th>  Log-Likelihood:    </th> <td> -14443.</td> \n","</tr>\n","<tr>\n","  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.889e+04</td>\n","</tr>\n","<tr>\n","  <th>Df Residuals:</th>          <td>  1164</td>      <th>  BIC:               </th> <td>2.891e+04</td>\n","</tr>\n","<tr>\n","  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>const</th> <td> 1.811e+05</td> <td> 1663.777</td> <td>  108.821</td> <td> 0.000</td> <td> 1.78e+05</td> <td> 1.84e+05</td>\n","</tr>\n","<tr>\n","  <th>x1</th>    <td> 5649.3615</td> <td> 1610.913</td> <td>    3.507</td> <td> 0.000</td> <td> 2488.743</td> <td> 8809.980</td>\n","</tr>\n","<tr>\n","  <th>x2</th>    <td> 3.772e+04</td> <td> 1912.254</td> <td>   19.727</td> <td> 0.000</td> <td>  3.4e+04</td> <td> 4.15e+04</td>\n","</tr>\n","<tr>\n","  <th>x3</th>    <td> 2.214e+04</td> <td> 1853.006</td> <td>   11.949</td> <td> 0.000</td> <td> 1.85e+04</td> <td> 2.58e+04</td>\n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","  <th>Omnibus:</th>       <td>441.037</td> <th>  Durbin-Watson:     </th> <td>   1.983</td>\n","</tr>\n","<tr>\n","  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2831.186</td>\n","</tr>\n","<tr>\n","  <th>Skew:</th>          <td> 1.602</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n","</tr>\n","<tr>\n","  <th>Kurtosis:</th>      <td> 9.922</td>  <th>  Cond. No.          </th> <td>    1.67</td>\n","</tr>\n","</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."],"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                      y   R-squared:                       0.460\n","Model:                            OLS   Adj. R-squared:                  0.459\n","Method:                 Least Squares   F-statistic:                     330.7\n","Date:                Tue, 19 Nov 2019   Prob (F-statistic):          2.90e-155\n","Time:                        17:18:50   Log-Likelihood:                -14443.\n","No. Observations:                1168   AIC:                         2.889e+04\n","Df Residuals:                    1164   BIC:                         2.891e+04\n","Df Model:                           3                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","const       1.811e+05   1663.777    108.821      0.000    1.78e+05    1.84e+05\n","x1          5649.3615   1610.913      3.507      0.000    2488.743    8809.980\n","x2          3.772e+04   1912.254     19.727      0.000     3.4e+04    4.15e+04\n","x3          2.214e+04   1853.006     11.949      0.000    1.85e+04    2.58e+04\n","==============================================================================\n","Omnibus:                      441.037   Durbin-Watson:                   1.983\n","Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2831.186\n","Skew:                           1.602   Prob(JB):                         0.00\n","Kurtosis:                       9.922   Cond. No.                         1.67\n","==============================================================================\n","\n","Warnings:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","\"\"\""]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"dvrcI3yIPaCH"},"source":["**Procedimento Final:** Todas as features acima estão dentro dentro intervalo de significância do modelo (SL = .05). Portanto, o processo de Bidirectional Elimination é finalizado e seguimos para o treinamento do modelo."]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"bd875a22-a62d-43dc-aa1b-6018b19f81e5","executionInfo":{"status":"ok","timestamp":1574183918726,"user_tz":180,"elapsed":1550,"user":{"displayName":"Jairo Souza","photoUrl":"","userId":"04219546553145172755"}},"id":"qeNjp4kJPaCI","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["regressor = LinearRegression()\n","regressor.fit(X_opt[:,1:], y_train)"],"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YlxnNQijPaCL"},"source":["Analisando o novo score do modelo com a métrica r2, exceto com a feature X2 (Índice 0 no conjunto de testes)"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"b2d465dc-5446-4e13-8a70-be8962671dfc","executionInfo":{"status":"ok","timestamp":1574183918727,"user_tz":180,"elapsed":1536,"user":{"displayName":"Jairo Souza","photoUrl":"","userId":"04219546553145172755"}},"id":"lNq3ZR-XPaCM","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["regressor.score(X_test[:, [1,2,3]], y_test)"],"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4484569043113157"]},"metadata":{"tags":[]},"execution_count":48}]}]}